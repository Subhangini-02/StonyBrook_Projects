{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd"],"metadata":{"id":"v70_2qFtPI-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading Data\n","\n","# data = pd.read_csv('breast-cancer.data')\n","# data = pd.read_csv('adult.data')\n","# # \n","# data = data.replace({'?': 0})\n","# data = data.dropna(axis=0) \n","# print(data.head())\n","\n","\n","# print(df.columns)\n","# df = pd.read_csv(\"obesity.csv\", on_bad_lines='skip') # Please Uncomment for external dataset \n","# df=df.drop(df.columns[1], axis=1)"],"metadata":{"id":"IQzFq_E6v1_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DSTreeNode: \n","    def __init__(self):\n","        self.left_child  = None\n","        self.right_child = None\n","        self.feature     = None\n","        self.threashold  = None \n","        \n","        self.leafv       = None\n","        \n","    def set_params(self,threashold, feature):\n","        self.threashold = threashold\n","        self.feature = feature    \n","        \n","    def set_children(self,left_child,right_child):\n","        self.left_child  = left_child\n","        self.right_child = right_child\n","\n","    def get_params(self):\n","        return (self.threashold,self.feature) \n","         "],"metadata":{"id":"jaqAiymlO3bo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_E1tVPrDORq8"},"outputs":[],"source":["class DecisionTreeClassifier: \n","    def __init__(self, max_depth, min_samples_split=2,loss='GINI'): \n","        self.tree              = None\n","        self.loss = loss   \n","        self.max_depth         = max_depth\n","        self.min_samples_split = min_samples_split \n","\n","\n","\n","    def predict_model(self,row, node=None): \n","        result = []\n","        for r in range(row.shape[0]):\n","            result.append(self.travel_tree(self.tree,row[r,:])) \n","        return(np.array(result).flatten())    \n","\n","    def travel_tree(self,node,rowdata): \n","      if node.leafv is not None: \n","          return(node.leafv)\n","      else: \n","          \n","          (s,f) = node.get_params() \n","          if (rowdata[f] <= s):\n","              return(self.travel_tree(node.left_child,rowdata))\n","          else:\n","              return(self.travel_tree(node.right_child,rowdata))\n","\n","    def calculate_node_impurity(self,table):  \n","        if self.loss == 'Gain_Ratio':\n","            imp = self.calculate_gain_ratio(table) \n","        elif self.loss == 'Information_Gain':\n","            imp = self.calculate_IG(table) \n","        elif self.loss == 'GINI':\n","            imp = self.calculate_gini_index(table) \n","        return(imp)\n","\n","    def calculate_gini_index(self,table): \n","        Gini = 0 \n","        for c in np.unique(table[:,-1]): \n","            p = table[table[:,-1]==c].shape[0]/table.shape[0] \n","            Gini += p*(1-p) \n","        return(Gini)\n","     \n","    def calculate_IG(self,table): \n","        Entropy = 0 \n","        for c in np.unique(table[:,-1]): \n","            p = table[table[:,-1]==c].shape[0]/table.shape[0] \n","            Entropy -= p*np.log2(p) \n","        return(Entropy)\n","     \n","    def calculate_gain_ratio(self,table): \n","        GR = 0 \n","        for c in np.unique(table[:,-1]): \n","            p = table[table[:,-1]==c].shape[0]/table.shape[0] \n","            \n","            GR += p*np.log2(p) \n","        return(GR)\n","\n","    \n","    \n","    def build_tree(self,node, table,level):     \n","\n","        table_right = table_left = split = ip_node = feature = None \n","\n","        msamp = (self.min_samples_split <= table.shape[0])\n","        depth = (self.max_depth is None) or (self.max_depth >= (level+1)) #left node check \n","        n_cls = np.unique(table[:,-1]).shape[0] != 1\n","         \n","        if not (depth and msamp and n_cls): \n","            node.leafv = self.check_leaf_value(table)\n","            return\n","         \n","        else:  \n","            for feat in range(table.shape[1]-1):\n","                for splt in np.unique(table[:,feat]): \n","                    table_low, table_high = table[table[:,feat]<=splt], table[table[:,feat]>splt]  # We are splitting to left and right \n","                    if table_low.size and table_high.size: \n","                        dl = (table_low.shape[0]/table.shape[0])*self.calculate_node_impurity(table_low)\n","                        dh = (table_high.shape[0]/table.shape[0])*self.calculate_node_impurity(table_high) \n","                        ip  =  dl + dh\n","                        if (ip_node is None) or (ip < ip_node):\n","                            ip_node, feature, split = ip, feat, splt \n","                            table_left, table_right  = table_low, table_high \n","\n","            node.set_params(split,feature)  \n","            node.set_children(DSTreeNode(),DSTreeNode()) \n","\n","            self.build_tree(node.right_child,table_right,level+1)\n","            self.build_tree(node.left_child,table_left,level+1)\n","             \n","    \n"," \n","    def train_model(self,row,c, n=\"\"): \n","        table = np.concatenate((row,c.reshape(-1,1)),axis=1) \n","        self.tree = DSTreeNode() \n","        self.build_tree(self.tree,table,1)\n","         \n","    \n"," \n","    def check_leaf_value(self,D):\n","         return(stats.mode(D[:,-1])[0])"]},{"cell_type":"code","source":[],"metadata":{"id":"7O_wHNwIz_fo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = load_breast_cancer()\n","\n","start_time = time.time()\n","X    = data.data\n","y    = data.target\n","nsampclass = 100\n","\n","y0, y1, X0, X1 = y[y==0], y[y==1], X[y==0], X[y==1] \n","\n","idx0 = np.random.choice([i for i in range(y0.shape[0])],size=nsampclass,replace=False)\n","idx1 = np.random.choice([i for i in range(y1.shape[0])],size=nsampclass,replace=False) \n","\n","y_train0, y_train1, X_train0, X_train1 = y0[idx0], y1[idx1], X0[idx0,:], X1[idx1,:] \n","y_train  = np.concatenate((y_train0,y_train1))\n","X_train  = np.concatenate((X_train0,X_train1))\n","\n","\n","y_test0, y_test1, X_test0, X_test1, y_test   = np.delete(y0,idx0), np.delete(y1,idx1), np.delete(X0,idx0,axis=0), np.delete(X1,idx1,axis=0), np.concatenate((y_test0,y_test1)) \n","X_test  = np.concatenate((X_test0,X_test1))\n","\n"," \n","clf = DecisionTreeClassifier(max_depth=5, loss = 'Information_Gain')\n","clf.train_model(X_train,y_train) \n","yp = clf.predict_model(X_test)\n","end_time = time.time()\n","print(\"Time Taken %s seconds\" % (round(end_time - start_time, 4)))\n","\n"],"metadata":{"id":"oB76RloQQbwB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668623275806,"user_tz":300,"elapsed":1179,"user":{"displayName":"Tanmay Rauth","userId":"07419307886164351011"}},"outputId":"de8ce1be-013c-41d3-8213-34e30189aad2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Time Taken 1.1469 seconds\n"]}]},{"cell_type":"code","source":["print(\"Data Accuracy: %.2f\" % accuracy_score(y_test,yp))\n","print(\"Data Sensitivity: %.2f\" % precision_score(y_test,yp))\n","print(\"Data Specificity: %.2f\" % recall_score(y_test,yp))\n"," "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZBaH5BCQd1O","executionInfo":{"status":"ok","timestamp":1668623275807,"user_tz":300,"elapsed":14,"user":{"displayName":"Tanmay Rauth","userId":"07419307886164351011"}},"outputId":"f946b158-04eb-4b66-8d1d-411cf7201d7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Accuracy: 0.90\n","Data Sensitivity: 0.97\n","Data Specificity: 0.88\n"]}]},{"cell_type":"code","source":["process = psutil.Process(os.getpid())\n","print(\"Total Used Memory for FP Growth Mining: \", end='')\n","print(process.memory_info().rss)"],"metadata":{"id":"lnc92jZGQf5G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668623275807,"user_tz":300,"elapsed":10,"user":{"displayName":"Tanmay Rauth","userId":"07419307886164351011"}},"outputId":"404663ec-2251-4a9d-ea5f-0b70f3f1e6c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Used Memory for FP Growth Mining: 199585792\n"]}]}]}